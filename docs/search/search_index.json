{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Warm Prompt WarmPrompt is a term I found on some printed manuals for electronic devices. Others have found it too. Let\u2019s begin with the important thing: \u201cwarm prompt\u201d is not bad English in the way that a typo is bad English. It\u2019s worse than that. It\u2019s perfectly grammatical , which means it survives quality control, while still being completely un-native. And that\u2019s always the most dangerous kind of mistake. What you\u2019re looking at here is not a linguistic failure but a category error caused by translation without cultural arbitration . In Chinese consumer communication, phrases like \u6e29\u99a8\u63d0\u793a don\u2019t describe temperature, emotion, or tone in the Western psychological sense. They describe intent . They signal: \u201cThis message is not trying to frighten you, fine you, or sue you.\u201d It\u2019s metadata, not mood. Now here\u2019s where it gets interesting. English doesn\u2019t label messages that way. English labels risk , severity , or obligation : Warning Caution Note Reminder Chinese labels relational posture : Friendly Considerate Polite When you translate word-for-word instead of function-for-function , you don\u2019t get clarity \u2014 you get a zombie phrase. Alive enough to walk, dead enough to confuse. \u201cWarm prompt\u201d survives because: Nobody is offended by it Everybody kind of understands it Nobody feels confident enough to fix it Which is exactly how bad design spreads. And notice where it appears: earbuds, power banks, smart watches \u2014 places where voice prompts exist but liability doesn\u2019t . These aren\u2019t safety warnings. They\u2019re not UX moments worth paying a native editor for. So the phrase persists, laminated into plastic, immortalised by tooling. This is what I\u2019d call manufacturing English \u2014 language that is optimized not for persuasion or comprehension, but for throughput . It is English as a checksum, not English as a user experience. The irony, of course, is that the phrase tries to be polite. It wants to reassure you. But in English, politeness doesn\u2019t work by adjectives \u2014 it works by implication and convention . We don\u2019t say something is warm; we simply make it harmless. So \u201cwarm prompt\u201d ends up doing the opposite of what it intends. It draws attention to itself. It makes you stop and think, \u201cWhy is this warm?\u201d And the moment your interface makes you ask a philosophical question, you\u2019ve already lost. In short: \u201cWarm prompt\u201d isn\u2019t wrong because it\u2019s unclear. It\u2019s wrong because it reveals the factory floor. And users can smell that instantly. So, I'd never use the term in professional docs, but here's where I write in the most unprofessional manner.","title":"Home"},{"location":"#warm-prompt","text":"WarmPrompt is a term I found on some printed manuals for electronic devices. Others have found it too. Let\u2019s begin with the important thing: \u201cwarm prompt\u201d is not bad English in the way that a typo is bad English. It\u2019s worse than that. It\u2019s perfectly grammatical , which means it survives quality control, while still being completely un-native. And that\u2019s always the most dangerous kind of mistake. What you\u2019re looking at here is not a linguistic failure but a category error caused by translation without cultural arbitration . In Chinese consumer communication, phrases like \u6e29\u99a8\u63d0\u793a don\u2019t describe temperature, emotion, or tone in the Western psychological sense. They describe intent . They signal: \u201cThis message is not trying to frighten you, fine you, or sue you.\u201d It\u2019s metadata, not mood. Now here\u2019s where it gets interesting. English doesn\u2019t label messages that way. English labels risk , severity , or obligation : Warning Caution Note Reminder Chinese labels relational posture : Friendly Considerate Polite When you translate word-for-word instead of function-for-function , you don\u2019t get clarity \u2014 you get a zombie phrase. Alive enough to walk, dead enough to confuse. \u201cWarm prompt\u201d survives because: Nobody is offended by it Everybody kind of understands it Nobody feels confident enough to fix it Which is exactly how bad design spreads. And notice where it appears: earbuds, power banks, smart watches \u2014 places where voice prompts exist but liability doesn\u2019t . These aren\u2019t safety warnings. They\u2019re not UX moments worth paying a native editor for. So the phrase persists, laminated into plastic, immortalised by tooling. This is what I\u2019d call manufacturing English \u2014 language that is optimized not for persuasion or comprehension, but for throughput . It is English as a checksum, not English as a user experience. The irony, of course, is that the phrase tries to be polite. It wants to reassure you. But in English, politeness doesn\u2019t work by adjectives \u2014 it works by implication and convention . We don\u2019t say something is warm; we simply make it harmless. So \u201cwarm prompt\u201d ends up doing the opposite of what it intends. It draws attention to itself. It makes you stop and think, \u201cWhy is this warm?\u201d And the moment your interface makes you ask a philosophical question, you\u2019ve already lost. In short: \u201cWarm prompt\u201d isn\u2019t wrong because it\u2019s unclear. It\u2019s wrong because it reveals the factory floor. And users can smell that instantly. So, I'd never use the term in professional docs, but here's where I write in the most unprofessional manner.","title":"Warm Prompt"}]}